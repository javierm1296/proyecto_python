{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de datos: <class 'numpy.ndarray'>\n",
      "Forma del dataset: (1460, 6)\n",
      "Primeras filas del dataset:\n",
      " [[208500.      7.    856.      8.   2003.     65.]\n",
      " [181500.      6.   1262.      6.   1976.     80.]\n",
      " [223500.      7.    920.      6.   2001.     68.]\n",
      " [140000.      7.    961.      7.   1915.     60.]\n",
      " [250000.      8.   1145.      9.   2000.     84.]\n",
      " [143000.      5.    796.      5.   1993.     85.]\n",
      " [307000.      8.   1694.      7.   2004.     75.]\n",
      " [200000.      7.   1107.      7.   1973.     nan]\n",
      " [129900.      7.   1022.      8.   1931.     51.]\n",
      " [118000.      5.   1077.      5.   1939.     50.]]\n"
     ]
    }
   ],
   "source": [
    "# Carga de archivo\n",
    "ruta_archivo = \"proyecto_training_data.npy\"\n",
    "datos = np.load(ruta_archivo)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Ver la estructura del dataset\n",
    "print(\"Tipo de datos:\", type(datos))\n",
    "print(\"Forma del dataset:\", datos.shape)\n",
    "print(\"Primeras filas del dataset:\\n\", datos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: (1168, 6)\n",
      "Tamaño del conjunto de validación: (292, 6)\n"
     ]
    }
   ],
   "source": [
    "# Dividir en entrenamiento (80%) y validación (20%)\n",
    "train_data, val_data = train_test_split(datos, test_size=0.2, random_state=2025)\n",
    "\n",
    "# Verificar tamaños\n",
    "print(\"Tamaño del conjunto de entrenamiento:\", train_data.shape)\n",
    "print(\"Tamaño del conjunto de validación:\", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: \n",
      "    SalePrice  OverallQual  1stFlrSF  TotRmsAbvGrd  YearBuilt  LotFrontage\n",
      "0   142000.0          5.0    1188.0           6.0     1959.0          NaN\n",
      "1   146000.0          7.0     703.0           5.0     2007.0         34.0\n",
      "2   256300.0          8.0    1600.0           7.0     2007.0        110.0\n",
      "3   128000.0          6.0     958.0           5.0     1976.0          NaN\n",
      "4    85000.0          5.0     536.0           4.0     1976.0         36.0\n",
      "Validación: \n",
      "    SalePrice  OverallQual  1stFlrSF  TotRmsAbvGrd  YearBuilt  LotFrontage\n",
      "0   147000.0          5.0     672.0           6.0     1920.0         59.0\n",
      "1   266000.0          9.0    1684.0           6.0     2005.0         63.0\n",
      "2   262280.0          7.0    1532.0          10.0     1990.0         86.0\n",
      "3   221500.0          7.0    1614.0           7.0     2005.0         86.0\n",
      "4   168000.0          4.0    1622.0           7.0     1961.0          NaN\n"
     ]
    }
   ],
   "source": [
    "# Convertir el dataset a un dataframe de pandas y asignar los datos correspondientes a entrenamiento y validación\n",
    "columnas = [\"SalePrice\", \"OverallQual\", \"1stFlrSF\", \"TotRmsAbvGrd\", \"YearBuilt\", \"LotFrontage\"]\n",
    "df = pd.DataFrame(datos, columns=columnas)\n",
    "df_train = pd.DataFrame(train_data, columns=columnas)\n",
    "df_val = pd.DataFrame(val_data, columns=columnas)\n",
    "\n",
    "# Mostrar primeras filas del conjunto de entrenamiento\n",
    "print(\"Entrenamiento: \\n\", df_train.head())\n",
    "\n",
    "# Mostrar primeras filas del conjunto de validación\n",
    "print(\"Validación: \\n\", df_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Variable  Blank Counts  NaN Counts\n",
      "SalePrice        SalePrice             0           0\n",
      "OverallQual    OverallQual             0           0\n",
      "1stFlrSF          1stFlrSF             0           0\n",
      "TotRmsAbvGrd  TotRmsAbvGrd             0           0\n",
      "YearBuilt        YearBuilt             0           0\n",
      "LotFrontage    LotFrontage             0         259\n"
     ]
    }
   ],
   "source": [
    "# Revisar NaN en cada columna 2\n",
    "nulls = df.isnull().sum()\n",
    "\n",
    "# Revisar blanks en cada columna\n",
    "blanks = (df == \"\").sum()\n",
    "\n",
    "blanks_nulls = pd.DataFrame({\n",
    "    'Variable': df.columns,\n",
    "    'Blank Counts': blanks,\n",
    "    'NaN Counts': nulls\n",
    "})\n",
    "print(blanks_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar nulls con media en LotFrontage (única columna con nulls)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "df[\"LotFrontage\"] = imputer.fit_transform(df[[\"LotFrontage\"]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           SalePrice  OverallQual     1stFlrSF  TotRmsAbvGrd    YearBuilt  \\\n",
      "count    1460.000000  1460.000000  1460.000000   1460.000000  1460.000000   \n",
      "mean   180921.195890     6.099315  1162.626712      6.517808  1971.267808   \n",
      "std     79442.502883     1.382997   386.587738      1.625393    30.202904   \n",
      "min     34900.000000     1.000000   334.000000      2.000000  1872.000000   \n",
      "25%    129975.000000     5.000000   882.000000      5.000000  1954.000000   \n",
      "50%    163000.000000     6.000000  1087.000000      6.000000  1973.000000   \n",
      "75%    214000.000000     7.000000  1391.250000      7.000000  2000.000000   \n",
      "max    755000.000000    10.000000  4692.000000     14.000000  2010.000000   \n",
      "\n",
      "       LotFrontage  \n",
      "count  1460.000000  \n",
      "mean     70.049958  \n",
      "std      22.024023  \n",
      "min      21.000000  \n",
      "25%      60.000000  \n",
      "50%      70.049958  \n",
      "75%      79.000000  \n",
      "max     313.000000  \n"
     ]
    }
   ],
   "source": [
    "# Resumen estadístico de los datos\n",
    "stats_df = df.describe()\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        SalePrice  OverallQual     1stFlrSF  TotRmsAbvGrd  \\\n",
      "Mean                180921.195890     6.099315  1162.626712      6.517808   \n",
      "Max                 755000.000000    10.000000  4692.000000     14.000000   \n",
      "Min                  34900.000000     1.000000   334.000000      2.000000   \n",
      "Range               720100.000000     9.000000  4358.000000     12.000000   \n",
      "Standard Deviation   79442.502883     1.382997   386.587738      1.625393   \n",
      "\n",
      "                      YearBuilt  LotFrontage  \n",
      "Mean                1971.267808    70.049958  \n",
      "Max                 2010.000000   313.000000  \n",
      "Min                 1872.000000    21.000000  \n",
      "Range                138.000000   292.000000  \n",
      "Standard Deviation    30.202904    22.024023  \n"
     ]
    }
   ],
   "source": [
    "# Resumen estadístico calculado \"manual\"\n",
    "stats = {\n",
    "    'Mean': df[columnas].mean(),\n",
    "    'Max': df[columnas].max(),\n",
    "    'Min': df[columnas].min(),\n",
    "    'Range': df[columnas].max() - df[columnas].min(),\n",
    "    'Standard Deviation': df[columnas].std()\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "stats_df = stats_df.T\n",
    "\n",
    "print(stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_ugal_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
